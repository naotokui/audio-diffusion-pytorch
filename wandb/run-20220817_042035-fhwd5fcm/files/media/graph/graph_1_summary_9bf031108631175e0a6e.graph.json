{"format": "torch", "nodes": [{"name": "model", "id": 46922188814032, "class_name": "Diffusion(\n  (net): UNet1d(\n    (to_in): Sequential(\n      (0): Rearrange('b c (l p) -> b (c p) l', p=16)\n      (1): CrossEmbed1d(\n        (convs): ModuleList(\n          (0): Conv1d(16, 64, kernel_size=(1,), stride=(1,))\n          (1): Conv1d(16, 32, kernel_size=(3,), stride=(1,), padding=(1,))\n          (2): Conv1d(16, 32, kernel_size=(7,), stride=(1,), padding=(3,))\n        )\n      )\n    )\n    (to_time): Sequential(\n      (0): Sequential(\n        (0): LearnedPositionalEmbedding()\n        (1): Linear(in_features=129, out_features=512, bias=True)\n      )\n      (1): SiLU()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n    )\n    (downsamples): ModuleList(\n      (0): DownsampleBlock1d(\n        (downsample): Conv1d(128, 256, kernel_size=(9,), stride=(4,), padding=(4,), groups=32)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=512, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=512, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n      )\n      (1): DownsampleBlock1d(\n        (downsample): Conv1d(256, 512, kernel_size=(9,), stride=(4,), padding=(4,), groups=64)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n      )\n      (2): DownsampleBlock1d(\n        (downsample): Conv1d(512, 512, kernel_size=(9,), stride=(4,), padding=(4,), groups=128)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n      )\n      (3): DownsampleBlock1d(\n        (downsample): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,), groups=128)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n      )\n      (4): DownsampleBlock1d(\n        (downsample): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,), groups=128)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n      )\n      (5): DownsampleBlock1d(\n        (downsample): Conv1d(512, 512, kernel_size=(5,), stride=(2,), padding=(2,), groups=128)\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Identity()\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n      )\n    )\n    (bottleneck): BottleneckBlock1d(\n      (pre_block): ResnetBlock1d(\n        (to_time_embedding): Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=512, out_features=1024, bias=True)\n        )\n        (block1): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (block2): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (to_out): Identity()\n      )\n      (attention): EinopsToAndFrom(\n        (fn): Attention(\n          (norm): LayerNorm()\n          (to_q): Linear(in_features=512, out_features=512, bias=False)\n          (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n          (attention): AttentionBase(\n            (insert_null_tokens): InsertNullTokens()\n            (to_out): Sequential(\n              (0): Linear(in_features=512, out_features=512, bias=False)\n              (1): LayerNorm()\n            )\n          )\n        )\n      )\n      (post_block): ResnetBlock1d(\n        (to_time_embedding): Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=512, out_features=1024, bias=True)\n        )\n        (block1): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (block2): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (to_out): Identity()\n      )\n    )\n    (upsamples): ModuleList(\n      (0): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (2): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n        (upsample): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n      )\n      (1): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (2): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n        (upsample): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n      )\n      (2): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (2): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (transformer): TransformerBlock1d(\n          (attention): EinopsToAndFrom(\n            (fn): Attention(\n              (norm): LayerNorm()\n              (to_q): Linear(in_features=512, out_features=512, bias=False)\n              (to_kv): Linear(in_features=512, out_features=1024, bias=False)\n              (attention): AttentionBase(\n                (insert_null_tokens): InsertNullTokens()\n                (to_out): Sequential(\n                  (0): Linear(in_features=512, out_features=512, bias=False)\n                  (1): LayerNorm()\n                )\n              )\n            )\n          )\n          (feed_forward): Sequential(\n            (0): LayerNorm1d()\n            (1): Conv1d(512, 1024, kernel_size=(1,), stride=(1,), bias=False)\n            (2): GELU(approximate=none)\n            (3): LayerNorm1d()\n            (4): Conv1d(1024, 512, kernel_size=(1,), stride=(1,), bias=False)\n          )\n        )\n        (upsample): ConvTranspose1d(512, 512, kernel_size=(4,), stride=(2,), padding=(1,))\n      )\n      (3): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (upsample): ConvTranspose1d(512, 512, kernel_size=(8,), stride=(4,), padding=(2,))\n      )\n      (4): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=1024, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 1024, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(1024, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 512, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(1024, 512, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (upsample): ConvTranspose1d(512, 256, kernel_size=(8,), stride=(4,), padding=(2,))\n      )\n      (5): UpsampleBlock1d(\n        (blocks): ModuleList(\n          (0): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=512, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n          )\n          (1): ResnetBlock1d(\n            (to_time_embedding): Sequential(\n              (0): SiLU()\n              (1): Linear(in_features=512, out_features=512, bias=True)\n            )\n            (block1): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 512, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(512, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (block2): ConvBlock1d(\n              (groupnorm): GroupNorm(8, 256, eps=1e-05, affine=True)\n              (activation): SiLU()\n              (project): Conv1d(256, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n            )\n            (to_out): Conv1d(512, 256, kernel_size=(1,), stride=(1,))\n          )\n        )\n        (upsample): ConvTranspose1d(256, 128, kernel_size=(8,), stride=(4,), padding=(2,))\n      )\n    )\n    (to_out): Sequential(\n      (0): ResnetBlock1d(\n        (to_time_embedding): Sequential(\n          (0): SiLU()\n          (1): Linear(in_features=512, out_features=256, bias=True)\n        )\n        (block1): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (block2): ConvBlock1d(\n          (groupnorm): GroupNorm(8, 128, eps=1e-05, affine=True)\n          (activation): SiLU()\n          (project): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n        )\n        (to_out): Identity()\n      )\n      (1): Conv1d(128, 16, kernel_size=(1,), stride=(1,))\n      (2): Rearrange('b (c p) l -> b c (l p)', p=16)\n    )\n  )\n)", "parameters": [["net.to_in.1.convs.0.weight", [64, 16, 1]], ["net.to_in.1.convs.0.bias", [64]], ["net.to_in.1.convs.1.weight", [32, 16, 3]], ["net.to_in.1.convs.1.bias", [32]], ["net.to_in.1.convs.2.weight", [32, 16, 7]], ["net.to_in.1.convs.2.bias", [32]], ["net.to_time.0.0.weights", [64]], ["net.to_time.0.1.weight", [512, 129]], ["net.to_time.0.1.bias", [512]], ["net.to_time.2.weight", [512, 512]], ["net.to_time.2.bias", [512]], ["net.downsamples.0.downsample.weight", [256, 4, 9]], ["net.downsamples.0.downsample.bias", [256]], ["net.downsamples.0.blocks.0.to_time_embedding.1.weight", [512, 512]], ["net.downsamples.0.blocks.0.to_time_embedding.1.bias", [512]], ["net.downsamples.0.blocks.0.block1.groupnorm.weight", [256]], ["net.downsamples.0.blocks.0.block1.groupnorm.bias", [256]], ["net.downsamples.0.blocks.0.block1.project.weight", [256, 256, 3]], ["net.downsamples.0.blocks.0.block1.project.bias", [256]], ["net.downsamples.0.blocks.0.block2.groupnorm.weight", [256]], ["net.downsamples.0.blocks.0.block2.groupnorm.bias", [256]], ["net.downsamples.0.blocks.0.block2.project.weight", [256, 256, 3]], ["net.downsamples.0.blocks.0.block2.project.bias", [256]], ["net.downsamples.0.blocks.1.to_time_embedding.1.weight", [512, 512]], ["net.downsamples.0.blocks.1.to_time_embedding.1.bias", [512]], ["net.downsamples.0.blocks.1.block1.groupnorm.weight", [256]], ["net.downsamples.0.blocks.1.block1.groupnorm.bias", [256]], ["net.downsamples.0.blocks.1.block1.project.weight", [256, 256, 3]], ["net.downsamples.0.blocks.1.block1.project.bias", [256]], ["net.downsamples.0.blocks.1.block2.groupnorm.weight", [256]], ["net.downsamples.0.blocks.1.block2.groupnorm.bias", [256]], ["net.downsamples.0.blocks.1.block2.project.weight", [256, 256, 3]], ["net.downsamples.0.blocks.1.block2.project.bias", [256]], ["net.downsamples.1.downsample.weight", [512, 4, 9]], ["net.downsamples.1.downsample.bias", [512]], ["net.downsamples.1.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.1.blocks.0.to_time_embedding.1.bias", [1024]], ["net.downsamples.1.blocks.0.block1.groupnorm.weight", [512]], ["net.downsamples.1.blocks.0.block1.groupnorm.bias", [512]], ["net.downsamples.1.blocks.0.block1.project.weight", [512, 512, 3]], ["net.downsamples.1.blocks.0.block1.project.bias", [512]], ["net.downsamples.1.blocks.0.block2.groupnorm.weight", [512]], ["net.downsamples.1.blocks.0.block2.groupnorm.bias", [512]], ["net.downsamples.1.blocks.0.block2.project.weight", [512, 512, 3]], ["net.downsamples.1.blocks.0.block2.project.bias", [512]], ["net.downsamples.1.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.1.blocks.1.to_time_embedding.1.bias", [1024]], ["net.downsamples.1.blocks.1.block1.groupnorm.weight", [512]], ["net.downsamples.1.blocks.1.block1.groupnorm.bias", [512]], ["net.downsamples.1.blocks.1.block1.project.weight", [512, 512, 3]], ["net.downsamples.1.blocks.1.block1.project.bias", [512]], ["net.downsamples.1.blocks.1.block2.groupnorm.weight", [512]], ["net.downsamples.1.blocks.1.block2.groupnorm.bias", [512]], ["net.downsamples.1.blocks.1.block2.project.weight", [512, 512, 3]], ["net.downsamples.1.blocks.1.block2.project.bias", [512]], ["net.downsamples.2.downsample.weight", [512, 4, 9]], ["net.downsamples.2.downsample.bias", [512]], ["net.downsamples.2.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.2.blocks.0.to_time_embedding.1.bias", [1024]], ["net.downsamples.2.blocks.0.block1.groupnorm.weight", [512]], ["net.downsamples.2.blocks.0.block1.groupnorm.bias", [512]], ["net.downsamples.2.blocks.0.block1.project.weight", [512, 512, 3]], ["net.downsamples.2.blocks.0.block1.project.bias", [512]], ["net.downsamples.2.blocks.0.block2.groupnorm.weight", [512]], ["net.downsamples.2.blocks.0.block2.groupnorm.bias", [512]], ["net.downsamples.2.blocks.0.block2.project.weight", [512, 512, 3]], ["net.downsamples.2.blocks.0.block2.project.bias", [512]], ["net.downsamples.2.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.2.blocks.1.to_time_embedding.1.bias", [1024]], ["net.downsamples.2.blocks.1.block1.groupnorm.weight", [512]], ["net.downsamples.2.blocks.1.block1.groupnorm.bias", [512]], ["net.downsamples.2.blocks.1.block1.project.weight", [512, 512, 3]], ["net.downsamples.2.blocks.1.block1.project.bias", [512]], ["net.downsamples.2.blocks.1.block2.groupnorm.weight", [512]], ["net.downsamples.2.blocks.1.block2.groupnorm.bias", [512]], ["net.downsamples.2.blocks.1.block2.project.weight", [512, 512, 3]], ["net.downsamples.2.blocks.1.block2.project.bias", [512]], ["net.downsamples.3.downsample.weight", [512, 4, 5]], ["net.downsamples.3.downsample.bias", [512]], ["net.downsamples.3.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.3.blocks.0.to_time_embedding.1.bias", [1024]], ["net.downsamples.3.blocks.0.block1.groupnorm.weight", [512]], ["net.downsamples.3.blocks.0.block1.groupnorm.bias", [512]], ["net.downsamples.3.blocks.0.block1.project.weight", [512, 512, 3]], ["net.downsamples.3.blocks.0.block1.project.bias", [512]], ["net.downsamples.3.blocks.0.block2.groupnorm.weight", [512]], ["net.downsamples.3.blocks.0.block2.groupnorm.bias", [512]], ["net.downsamples.3.blocks.0.block2.project.weight", [512, 512, 3]], ["net.downsamples.3.blocks.0.block2.project.bias", [512]], ["net.downsamples.3.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.3.blocks.1.to_time_embedding.1.bias", [1024]], ["net.downsamples.3.blocks.1.block1.groupnorm.weight", [512]], ["net.downsamples.3.blocks.1.block1.groupnorm.bias", [512]], ["net.downsamples.3.blocks.1.block1.project.weight", [512, 512, 3]], ["net.downsamples.3.blocks.1.block1.project.bias", [512]], ["net.downsamples.3.blocks.1.block2.groupnorm.weight", [512]], ["net.downsamples.3.blocks.1.block2.groupnorm.bias", [512]], ["net.downsamples.3.blocks.1.block2.project.weight", [512, 512, 3]], ["net.downsamples.3.blocks.1.block2.project.bias", [512]], ["net.downsamples.3.transformer.attention.fn.norm.g", [512]], ["net.downsamples.3.transformer.attention.fn.to_q.weight", [512, 512]], ["net.downsamples.3.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.downsamples.3.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.downsamples.3.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.downsamples.3.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.downsamples.3.transformer.feed_forward.0.g", [1, 512, 1]], ["net.downsamples.3.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.downsamples.3.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.downsamples.3.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.downsamples.4.downsample.weight", [512, 4, 5]], ["net.downsamples.4.downsample.bias", [512]], ["net.downsamples.4.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.4.blocks.0.to_time_embedding.1.bias", [1024]], ["net.downsamples.4.blocks.0.block1.groupnorm.weight", [512]], ["net.downsamples.4.blocks.0.block1.groupnorm.bias", [512]], ["net.downsamples.4.blocks.0.block1.project.weight", [512, 512, 3]], ["net.downsamples.4.blocks.0.block1.project.bias", [512]], ["net.downsamples.4.blocks.0.block2.groupnorm.weight", [512]], ["net.downsamples.4.blocks.0.block2.groupnorm.bias", [512]], ["net.downsamples.4.blocks.0.block2.project.weight", [512, 512, 3]], ["net.downsamples.4.blocks.0.block2.project.bias", [512]], ["net.downsamples.4.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.4.blocks.1.to_time_embedding.1.bias", [1024]], ["net.downsamples.4.blocks.1.block1.groupnorm.weight", [512]], ["net.downsamples.4.blocks.1.block1.groupnorm.bias", [512]], ["net.downsamples.4.blocks.1.block1.project.weight", [512, 512, 3]], ["net.downsamples.4.blocks.1.block1.project.bias", [512]], ["net.downsamples.4.blocks.1.block2.groupnorm.weight", [512]], ["net.downsamples.4.blocks.1.block2.groupnorm.bias", [512]], ["net.downsamples.4.blocks.1.block2.project.weight", [512, 512, 3]], ["net.downsamples.4.blocks.1.block2.project.bias", [512]], ["net.downsamples.4.transformer.attention.fn.norm.g", [512]], ["net.downsamples.4.transformer.attention.fn.to_q.weight", [512, 512]], ["net.downsamples.4.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.downsamples.4.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.downsamples.4.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.downsamples.4.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.downsamples.4.transformer.feed_forward.0.g", [1, 512, 1]], ["net.downsamples.4.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.downsamples.4.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.downsamples.4.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.downsamples.5.downsample.weight", [512, 4, 5]], ["net.downsamples.5.downsample.bias", [512]], ["net.downsamples.5.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.5.blocks.0.to_time_embedding.1.bias", [1024]], ["net.downsamples.5.blocks.0.block1.groupnorm.weight", [512]], ["net.downsamples.5.blocks.0.block1.groupnorm.bias", [512]], ["net.downsamples.5.blocks.0.block1.project.weight", [512, 512, 3]], ["net.downsamples.5.blocks.0.block1.project.bias", [512]], ["net.downsamples.5.blocks.0.block2.groupnorm.weight", [512]], ["net.downsamples.5.blocks.0.block2.groupnorm.bias", [512]], ["net.downsamples.5.blocks.0.block2.project.weight", [512, 512, 3]], ["net.downsamples.5.blocks.0.block2.project.bias", [512]], ["net.downsamples.5.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.downsamples.5.blocks.1.to_time_embedding.1.bias", [1024]], ["net.downsamples.5.blocks.1.block1.groupnorm.weight", [512]], ["net.downsamples.5.blocks.1.block1.groupnorm.bias", [512]], ["net.downsamples.5.blocks.1.block1.project.weight", [512, 512, 3]], ["net.downsamples.5.blocks.1.block1.project.bias", [512]], ["net.downsamples.5.blocks.1.block2.groupnorm.weight", [512]], ["net.downsamples.5.blocks.1.block2.groupnorm.bias", [512]], ["net.downsamples.5.blocks.1.block2.project.weight", [512, 512, 3]], ["net.downsamples.5.blocks.1.block2.project.bias", [512]], ["net.downsamples.5.transformer.attention.fn.norm.g", [512]], ["net.downsamples.5.transformer.attention.fn.to_q.weight", [512, 512]], ["net.downsamples.5.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.downsamples.5.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.downsamples.5.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.downsamples.5.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.downsamples.5.transformer.feed_forward.0.g", [1, 512, 1]], ["net.downsamples.5.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.downsamples.5.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.downsamples.5.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.bottleneck.pre_block.to_time_embedding.1.weight", [1024, 512]], ["net.bottleneck.pre_block.to_time_embedding.1.bias", [1024]], ["net.bottleneck.pre_block.block1.groupnorm.weight", [512]], ["net.bottleneck.pre_block.block1.groupnorm.bias", [512]], ["net.bottleneck.pre_block.block1.project.weight", [512, 512, 3]], ["net.bottleneck.pre_block.block1.project.bias", [512]], ["net.bottleneck.pre_block.block2.groupnorm.weight", [512]], ["net.bottleneck.pre_block.block2.groupnorm.bias", [512]], ["net.bottleneck.pre_block.block2.project.weight", [512, 512, 3]], ["net.bottleneck.pre_block.block2.project.bias", [512]], ["net.bottleneck.attention.fn.norm.g", [512]], ["net.bottleneck.attention.fn.to_q.weight", [512, 512]], ["net.bottleneck.attention.fn.to_kv.weight", [1024, 512]], ["net.bottleneck.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.bottleneck.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.bottleneck.attention.fn.attention.to_out.1.g", [512]], ["net.bottleneck.post_block.to_time_embedding.1.weight", [1024, 512]], ["net.bottleneck.post_block.to_time_embedding.1.bias", [1024]], ["net.bottleneck.post_block.block1.groupnorm.weight", [512]], ["net.bottleneck.post_block.block1.groupnorm.bias", [512]], ["net.bottleneck.post_block.block1.project.weight", [512, 512, 3]], ["net.bottleneck.post_block.block1.project.bias", [512]], ["net.bottleneck.post_block.block2.groupnorm.weight", [512]], ["net.bottleneck.post_block.block2.groupnorm.bias", [512]], ["net.bottleneck.post_block.block2.project.weight", [512, 512, 3]], ["net.bottleneck.post_block.block2.project.bias", [512]], ["net.upsamples.0.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.0.blocks.0.to_time_embedding.1.bias", [1024]], ["net.upsamples.0.blocks.0.block1.groupnorm.weight", [1024]], ["net.upsamples.0.blocks.0.block1.groupnorm.bias", [1024]], ["net.upsamples.0.blocks.0.block1.project.weight", [512, 1024, 3]], ["net.upsamples.0.blocks.0.block1.project.bias", [512]], ["net.upsamples.0.blocks.0.block2.groupnorm.weight", [512]], ["net.upsamples.0.blocks.0.block2.groupnorm.bias", [512]], ["net.upsamples.0.blocks.0.block2.project.weight", [512, 512, 3]], ["net.upsamples.0.blocks.0.block2.project.bias", [512]], ["net.upsamples.0.blocks.0.to_out.weight", [512, 1024, 1]], ["net.upsamples.0.blocks.0.to_out.bias", [512]], ["net.upsamples.0.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.0.blocks.1.to_time_embedding.1.bias", [1024]], ["net.upsamples.0.blocks.1.block1.groupnorm.weight", [1024]], ["net.upsamples.0.blocks.1.block1.groupnorm.bias", [1024]], ["net.upsamples.0.blocks.1.block1.project.weight", [512, 1024, 3]], ["net.upsamples.0.blocks.1.block1.project.bias", [512]], ["net.upsamples.0.blocks.1.block2.groupnorm.weight", [512]], ["net.upsamples.0.blocks.1.block2.groupnorm.bias", [512]], ["net.upsamples.0.blocks.1.block2.project.weight", [512, 512, 3]], ["net.upsamples.0.blocks.1.block2.project.bias", [512]], ["net.upsamples.0.blocks.1.to_out.weight", [512, 1024, 1]], ["net.upsamples.0.blocks.1.to_out.bias", [512]], ["net.upsamples.0.blocks.2.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.0.blocks.2.to_time_embedding.1.bias", [1024]], ["net.upsamples.0.blocks.2.block1.groupnorm.weight", [1024]], ["net.upsamples.0.blocks.2.block1.groupnorm.bias", [1024]], ["net.upsamples.0.blocks.2.block1.project.weight", [512, 1024, 3]], ["net.upsamples.0.blocks.2.block1.project.bias", [512]], ["net.upsamples.0.blocks.2.block2.groupnorm.weight", [512]], ["net.upsamples.0.blocks.2.block2.groupnorm.bias", [512]], ["net.upsamples.0.blocks.2.block2.project.weight", [512, 512, 3]], ["net.upsamples.0.blocks.2.block2.project.bias", [512]], ["net.upsamples.0.blocks.2.to_out.weight", [512, 1024, 1]], ["net.upsamples.0.blocks.2.to_out.bias", [512]], ["net.upsamples.0.transformer.attention.fn.norm.g", [512]], ["net.upsamples.0.transformer.attention.fn.to_q.weight", [512, 512]], ["net.upsamples.0.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.upsamples.0.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.upsamples.0.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.upsamples.0.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.upsamples.0.transformer.feed_forward.0.g", [1, 512, 1]], ["net.upsamples.0.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.upsamples.0.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.upsamples.0.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.upsamples.0.upsample.weight", [512, 512, 4]], ["net.upsamples.0.upsample.bias", [512]], ["net.upsamples.1.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.1.blocks.0.to_time_embedding.1.bias", [1024]], ["net.upsamples.1.blocks.0.block1.groupnorm.weight", [1024]], ["net.upsamples.1.blocks.0.block1.groupnorm.bias", [1024]], ["net.upsamples.1.blocks.0.block1.project.weight", [512, 1024, 3]], ["net.upsamples.1.blocks.0.block1.project.bias", [512]], ["net.upsamples.1.blocks.0.block2.groupnorm.weight", [512]], ["net.upsamples.1.blocks.0.block2.groupnorm.bias", [512]], ["net.upsamples.1.blocks.0.block2.project.weight", [512, 512, 3]], ["net.upsamples.1.blocks.0.block2.project.bias", [512]], ["net.upsamples.1.blocks.0.to_out.weight", [512, 1024, 1]], ["net.upsamples.1.blocks.0.to_out.bias", [512]], ["net.upsamples.1.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.1.blocks.1.to_time_embedding.1.bias", [1024]], ["net.upsamples.1.blocks.1.block1.groupnorm.weight", [1024]], ["net.upsamples.1.blocks.1.block1.groupnorm.bias", [1024]], ["net.upsamples.1.blocks.1.block1.project.weight", [512, 1024, 3]], ["net.upsamples.1.blocks.1.block1.project.bias", [512]], ["net.upsamples.1.blocks.1.block2.groupnorm.weight", [512]], ["net.upsamples.1.blocks.1.block2.groupnorm.bias", [512]], ["net.upsamples.1.blocks.1.block2.project.weight", [512, 512, 3]], ["net.upsamples.1.blocks.1.block2.project.bias", [512]], ["net.upsamples.1.blocks.1.to_out.weight", [512, 1024, 1]], ["net.upsamples.1.blocks.1.to_out.bias", [512]], ["net.upsamples.1.blocks.2.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.1.blocks.2.to_time_embedding.1.bias", [1024]], ["net.upsamples.1.blocks.2.block1.groupnorm.weight", [1024]], ["net.upsamples.1.blocks.2.block1.groupnorm.bias", [1024]], ["net.upsamples.1.blocks.2.block1.project.weight", [512, 1024, 3]], ["net.upsamples.1.blocks.2.block1.project.bias", [512]], ["net.upsamples.1.blocks.2.block2.groupnorm.weight", [512]], ["net.upsamples.1.blocks.2.block2.groupnorm.bias", [512]], ["net.upsamples.1.blocks.2.block2.project.weight", [512, 512, 3]], ["net.upsamples.1.blocks.2.block2.project.bias", [512]], ["net.upsamples.1.blocks.2.to_out.weight", [512, 1024, 1]], ["net.upsamples.1.blocks.2.to_out.bias", [512]], ["net.upsamples.1.transformer.attention.fn.norm.g", [512]], ["net.upsamples.1.transformer.attention.fn.to_q.weight", [512, 512]], ["net.upsamples.1.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.upsamples.1.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.upsamples.1.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.upsamples.1.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.upsamples.1.transformer.feed_forward.0.g", [1, 512, 1]], ["net.upsamples.1.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.upsamples.1.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.upsamples.1.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.upsamples.1.upsample.weight", [512, 512, 4]], ["net.upsamples.1.upsample.bias", [512]], ["net.upsamples.2.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.2.blocks.0.to_time_embedding.1.bias", [1024]], ["net.upsamples.2.blocks.0.block1.groupnorm.weight", [1024]], ["net.upsamples.2.blocks.0.block1.groupnorm.bias", [1024]], ["net.upsamples.2.blocks.0.block1.project.weight", [512, 1024, 3]], ["net.upsamples.2.blocks.0.block1.project.bias", [512]], ["net.upsamples.2.blocks.0.block2.groupnorm.weight", [512]], ["net.upsamples.2.blocks.0.block2.groupnorm.bias", [512]], ["net.upsamples.2.blocks.0.block2.project.weight", [512, 512, 3]], ["net.upsamples.2.blocks.0.block2.project.bias", [512]], ["net.upsamples.2.blocks.0.to_out.weight", [512, 1024, 1]], ["net.upsamples.2.blocks.0.to_out.bias", [512]], ["net.upsamples.2.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.2.blocks.1.to_time_embedding.1.bias", [1024]], ["net.upsamples.2.blocks.1.block1.groupnorm.weight", [1024]], ["net.upsamples.2.blocks.1.block1.groupnorm.bias", [1024]], ["net.upsamples.2.blocks.1.block1.project.weight", [512, 1024, 3]], ["net.upsamples.2.blocks.1.block1.project.bias", [512]], ["net.upsamples.2.blocks.1.block2.groupnorm.weight", [512]], ["net.upsamples.2.blocks.1.block2.groupnorm.bias", [512]], ["net.upsamples.2.blocks.1.block2.project.weight", [512, 512, 3]], ["net.upsamples.2.blocks.1.block2.project.bias", [512]], ["net.upsamples.2.blocks.1.to_out.weight", [512, 1024, 1]], ["net.upsamples.2.blocks.1.to_out.bias", [512]], ["net.upsamples.2.blocks.2.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.2.blocks.2.to_time_embedding.1.bias", [1024]], ["net.upsamples.2.blocks.2.block1.groupnorm.weight", [1024]], ["net.upsamples.2.blocks.2.block1.groupnorm.bias", [1024]], ["net.upsamples.2.blocks.2.block1.project.weight", [512, 1024, 3]], ["net.upsamples.2.blocks.2.block1.project.bias", [512]], ["net.upsamples.2.blocks.2.block2.groupnorm.weight", [512]], ["net.upsamples.2.blocks.2.block2.groupnorm.bias", [512]], ["net.upsamples.2.blocks.2.block2.project.weight", [512, 512, 3]], ["net.upsamples.2.blocks.2.block2.project.bias", [512]], ["net.upsamples.2.blocks.2.to_out.weight", [512, 1024, 1]], ["net.upsamples.2.blocks.2.to_out.bias", [512]], ["net.upsamples.2.transformer.attention.fn.norm.g", [512]], ["net.upsamples.2.transformer.attention.fn.to_q.weight", [512, 512]], ["net.upsamples.2.transformer.attention.fn.to_kv.weight", [1024, 512]], ["net.upsamples.2.transformer.attention.fn.attention.insert_null_tokens.tokens", [2, 64]], ["net.upsamples.2.transformer.attention.fn.attention.to_out.0.weight", [512, 512]], ["net.upsamples.2.transformer.attention.fn.attention.to_out.1.g", [512]], ["net.upsamples.2.transformer.feed_forward.0.g", [1, 512, 1]], ["net.upsamples.2.transformer.feed_forward.1.weight", [1024, 512, 1]], ["net.upsamples.2.transformer.feed_forward.3.g", [1, 1024, 1]], ["net.upsamples.2.transformer.feed_forward.4.weight", [512, 1024, 1]], ["net.upsamples.2.upsample.weight", [512, 512, 4]], ["net.upsamples.2.upsample.bias", [512]], ["net.upsamples.3.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.3.blocks.0.to_time_embedding.1.bias", [1024]], ["net.upsamples.3.blocks.0.block1.groupnorm.weight", [1024]], ["net.upsamples.3.blocks.0.block1.groupnorm.bias", [1024]], ["net.upsamples.3.blocks.0.block1.project.weight", [512, 1024, 3]], ["net.upsamples.3.blocks.0.block1.project.bias", [512]], ["net.upsamples.3.blocks.0.block2.groupnorm.weight", [512]], ["net.upsamples.3.blocks.0.block2.groupnorm.bias", [512]], ["net.upsamples.3.blocks.0.block2.project.weight", [512, 512, 3]], ["net.upsamples.3.blocks.0.block2.project.bias", [512]], ["net.upsamples.3.blocks.0.to_out.weight", [512, 1024, 1]], ["net.upsamples.3.blocks.0.to_out.bias", [512]], ["net.upsamples.3.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.3.blocks.1.to_time_embedding.1.bias", [1024]], ["net.upsamples.3.blocks.1.block1.groupnorm.weight", [1024]], ["net.upsamples.3.blocks.1.block1.groupnorm.bias", [1024]], ["net.upsamples.3.blocks.1.block1.project.weight", [512, 1024, 3]], ["net.upsamples.3.blocks.1.block1.project.bias", [512]], ["net.upsamples.3.blocks.1.block2.groupnorm.weight", [512]], ["net.upsamples.3.blocks.1.block2.groupnorm.bias", [512]], ["net.upsamples.3.blocks.1.block2.project.weight", [512, 512, 3]], ["net.upsamples.3.blocks.1.block2.project.bias", [512]], ["net.upsamples.3.blocks.1.to_out.weight", [512, 1024, 1]], ["net.upsamples.3.blocks.1.to_out.bias", [512]], ["net.upsamples.3.upsample.weight", [512, 512, 8]], ["net.upsamples.3.upsample.bias", [512]], ["net.upsamples.4.blocks.0.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.4.blocks.0.to_time_embedding.1.bias", [1024]], ["net.upsamples.4.blocks.0.block1.groupnorm.weight", [1024]], ["net.upsamples.4.blocks.0.block1.groupnorm.bias", [1024]], ["net.upsamples.4.blocks.0.block1.project.weight", [512, 1024, 3]], ["net.upsamples.4.blocks.0.block1.project.bias", [512]], ["net.upsamples.4.blocks.0.block2.groupnorm.weight", [512]], ["net.upsamples.4.blocks.0.block2.groupnorm.bias", [512]], ["net.upsamples.4.blocks.0.block2.project.weight", [512, 512, 3]], ["net.upsamples.4.blocks.0.block2.project.bias", [512]], ["net.upsamples.4.blocks.0.to_out.weight", [512, 1024, 1]], ["net.upsamples.4.blocks.0.to_out.bias", [512]], ["net.upsamples.4.blocks.1.to_time_embedding.1.weight", [1024, 512]], ["net.upsamples.4.blocks.1.to_time_embedding.1.bias", [1024]], ["net.upsamples.4.blocks.1.block1.groupnorm.weight", [1024]], ["net.upsamples.4.blocks.1.block1.groupnorm.bias", [1024]], ["net.upsamples.4.blocks.1.block1.project.weight", [512, 1024, 3]], ["net.upsamples.4.blocks.1.block1.project.bias", [512]], ["net.upsamples.4.blocks.1.block2.groupnorm.weight", [512]], ["net.upsamples.4.blocks.1.block2.groupnorm.bias", [512]], ["net.upsamples.4.blocks.1.block2.project.weight", [512, 512, 3]], ["net.upsamples.4.blocks.1.block2.project.bias", [512]], ["net.upsamples.4.blocks.1.to_out.weight", [512, 1024, 1]], ["net.upsamples.4.blocks.1.to_out.bias", [512]], ["net.upsamples.4.upsample.weight", [512, 256, 8]], ["net.upsamples.4.upsample.bias", [256]], ["net.upsamples.5.blocks.0.to_time_embedding.1.weight", [512, 512]], ["net.upsamples.5.blocks.0.to_time_embedding.1.bias", [512]], ["net.upsamples.5.blocks.0.block1.groupnorm.weight", [512]], ["net.upsamples.5.blocks.0.block1.groupnorm.bias", [512]], ["net.upsamples.5.blocks.0.block1.project.weight", [256, 512, 3]], ["net.upsamples.5.blocks.0.block1.project.bias", [256]], ["net.upsamples.5.blocks.0.block2.groupnorm.weight", [256]], ["net.upsamples.5.blocks.0.block2.groupnorm.bias", [256]], ["net.upsamples.5.blocks.0.block2.project.weight", [256, 256, 3]], ["net.upsamples.5.blocks.0.block2.project.bias", [256]], ["net.upsamples.5.blocks.0.to_out.weight", [256, 512, 1]], ["net.upsamples.5.blocks.0.to_out.bias", [256]], ["net.upsamples.5.blocks.1.to_time_embedding.1.weight", [512, 512]], ["net.upsamples.5.blocks.1.to_time_embedding.1.bias", [512]], ["net.upsamples.5.blocks.1.block1.groupnorm.weight", [512]], ["net.upsamples.5.blocks.1.block1.groupnorm.bias", [512]], ["net.upsamples.5.blocks.1.block1.project.weight", [256, 512, 3]], ["net.upsamples.5.blocks.1.block1.project.bias", [256]], ["net.upsamples.5.blocks.1.block2.groupnorm.weight", [256]], ["net.upsamples.5.blocks.1.block2.groupnorm.bias", [256]], ["net.upsamples.5.blocks.1.block2.project.weight", [256, 256, 3]], ["net.upsamples.5.blocks.1.block2.project.bias", [256]], ["net.upsamples.5.blocks.1.to_out.weight", [256, 512, 1]], ["net.upsamples.5.blocks.1.to_out.bias", [256]], ["net.upsamples.5.upsample.weight", [256, 128, 8]], ["net.upsamples.5.upsample.bias", [128]], ["net.to_out.0.to_time_embedding.1.weight", [256, 512]], ["net.to_out.0.to_time_embedding.1.bias", [256]], ["net.to_out.0.block1.groupnorm.weight", [128]], ["net.to_out.0.block1.groupnorm.bias", [128]], ["net.to_out.0.block1.project.weight", [128, 128, 3]], ["net.to_out.0.block1.project.bias", [128]], ["net.to_out.0.block2.groupnorm.weight", [128]], ["net.to_out.0.block2.groupnorm.bias", [128]], ["net.to_out.0.block2.project.weight", [128, 128, 3]], ["net.to_out.0.block2.project.bias", [128]], ["net.to_out.1.weight", [16, 128, 1]], ["net.to_out.1.bias", [16]]], "output_shape": [[]], "num_parameters": [1024, 64, 1536, 32, 3584, 32, 64, 66048, 512, 262144, 512, 9216, 256, 262144, 512, 256, 256, 196608, 256, 256, 256, 196608, 256, 262144, 512, 256, 256, 196608, 256, 256, 256, 196608, 256, 18432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 18432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 10240, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 10240, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 10240, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 512, 262144, 524288, 128, 262144, 512, 524288, 1024, 512, 512, 786432, 512, 512, 512, 786432, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 1048576, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 1048576, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 512, 262144, 524288, 128, 262144, 512, 512, 524288, 1024, 524288, 1048576, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 2097152, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 524288, 1024, 1024, 1024, 1572864, 512, 512, 512, 786432, 512, 524288, 512, 1048576, 256, 262144, 512, 512, 512, 393216, 256, 256, 256, 196608, 256, 131072, 256, 262144, 512, 512, 512, 393216, 256, 256, 256, 196608, 256, 131072, 256, 262144, 128, 131072, 256, 128, 128, 49152, 128, 128, 128, 49152, 128, 2048, 16]}], "edges": []}