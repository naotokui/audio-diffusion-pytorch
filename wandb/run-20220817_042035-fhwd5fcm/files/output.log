
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
/home/nao/anaconda3/envs/p37/lib/python3.7/site-packages/torch/cuda/__init__.py:146: UserWarning:
NVIDIA RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the NVIDIA RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/
  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type      | Params
------------------------------------
0 | model | Diffusion | 93.7 M
------------------------------------
93.7 M    Trainable params
0         Non-trainable params
93.7 M    Total params
374.918   Total estimated model params size (MB)
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type      | Params
------------------------------------
0 | model | Diffusion | 93.7 M
------------------------------------
93.7 M    Trainable params
0         Non-trainable params
93.7 M    Total params
374.918   Total estimated model params size (MB)
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
/home/nao/anaconda3/envs/p37/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:446: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.
  f"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed"
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type      | Params
------------------------------------
0 | model | Diffusion | 93.7 M
------------------------------------
93.7 M    Trainable params
0         Non-trainable params
93.7 M    Total params
374.918   Total estimated model params size (MB)
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
<torch.utils.data.dataloader.DataLoader object at 0x2aacec6251d0>
<torch.utils.data.dataloader.DataLoader object at 0x2aacec623650>
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
<torch.utils.data.dataloader.DataLoader object at 0x2aacec5fc1d0> 23
<torch.utils.data.dataloader.DataLoader object at 0x2aacec5da410>
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
Global seed set to 1000
417
375
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
417
375
Global seed set to 1000
<torch.utils.data.dataloader.DataLoader object at 0x2aacec630110> 23
<torch.utils.data.dataloader.DataLoader object at 0x2aacec5fc1d0>
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/nao/anaconda3/envs/p37/lib/python3.7/site-packages/pytorch_lightning/loggers/wandb.py:352: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  "There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse"
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
torch.Size([1, 1, 524288])
torch.Size([1, 1, 262144])
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
torch.Size([1, 1, 262144])
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
[34m[1mwandb[39m[22m: logging graph, to disable use `wandb.watch(log_graph=False)`
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]
  | Name  | Type      | Params
------------------------------------
0 | model | Diffusion | 93.7 M
------------------------------------
93.7 M    Trainable params
0         Non-trainable params
93.7 M    Total params
374.918   Total estimated model params size (MB)
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
{"AudioDiffusionModel": "type", "Callback": "type", "Crop": "type", "DataLoader": "type", "Diffusion": "type", "DiffusionModel": "type", "EarlyStopping": "type", "LightningBase": "type", "LightningModule": "type", "LogNormalDistribution": "type", "ModelCheckpoint": "type", "N_SAMPLES": "int", "TensorBoardLogger": "ABCMeta", "Trainer": "ABCMeta", "UNet1d": "type", "WAVDataset": "type", "WandbLogger": "ABCMeta", "a": "Tensor", "batch_size": "int", "crop": "Crop", "dataset": "WAVDataset", "diff_model": "DiffusionModel", "diffusion": "Diffusion", "dirpath": "str", "filename": "str", "get_ipython": "function", "nb_train_samples": "int", "nb_val_samples": "int", "num_workers": "int", "os": "module", "project_root": "str", "seed_everything": "function", "sys": "module", "tensorboard_logger": "TensorBoardLogger", "time": "module", "torch": "module", "train_dataset": "Subset", "train_loader": "DataLoader", "trainer": "Trainer", "unet": "UNet1d", "val_dataset": "Subset", "valid_loader": "DataLoader", "wandb_logger": "WandbLogger"}
torch.Size([1, 1, 262144])
